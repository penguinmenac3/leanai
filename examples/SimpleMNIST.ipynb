{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b88fe4c0-f7e5-4c78-a967-f97f60df1e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305b8f65-8354-4254-b475-ad9179fb0d24",
   "metadata": {},
   "source": [
    "# Example: Simple MNIST\n",
    "\n",
    "> In this example we will not learn a lot of details, we will just run fashion mnist as quick as possible to teach the basics.\n",
    "\n",
    "This example shows how to solve fashion MNIST in the simplest way with leanai.\n",
    "We need barely any code.\n",
    "\n",
    "Just import everything and then create and run an experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f482afa8-2450-46fe-bb08-0e79c3c03b53",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "We will need:\n",
    "1. Dataset,\n",
    "2. model,\n",
    "3. loss,\n",
    "4. optimizer,\n",
    "5. and a training loop.\n",
    "\n",
    "Luckily they are either provided by torch or by leanai. Let's just import everything for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc9af183-e65f-46f9-a75c-ff4f83c7dddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import SGD\n",
    "\n",
    "from leanai.core.config import DictLike\n",
    "from leanai.core.experiment import Experiment, set_seeds\n",
    "from leanai.data.datasets import FashionMNISTDataset\n",
    "from leanai.training.losses import SparseCrossEntropyLossFromLogits\n",
    "from leanai.model.configs.simple_classifier import buildSimpleClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3419612-8b44-4f23-ad3d-9825262dc45b",
   "metadata": {},
   "source": [
    "## Experiment\n",
    "\n",
    "First, before we do anything, we set our seeds, so that the hole experiment will be reproducible.\n",
    "We want to be able to get the same results, when running the code twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22c76959-f206-453c-8956-ac274de86210",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163d8000-8a38-4fa7-9afb-e623ced8d5d3",
   "metadata": {},
   "source": [
    "Next will to be creating an experiment. The experiment will tie everything together.\n",
    "\n",
    "An experiment can have various attributes, but the minimal requirement is a model.\n",
    "We will also provide a folder where outputs are stored and an example input.\n",
    "The example input is used to initialize the model and log a tensorboard graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6fc8333-3b5c-40da-b815-f49f234e1e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(\n",
    "    model=buildSimpleClassifier(num_classes=10, logits=True),\n",
    "    output_path=\"outputs\",\n",
    "    example_input=torch.zeros((2, 28, 28, 1), dtype=torch.float32),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f42f1a3-f1ec-4768-8981-eedbbbb84c2a",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Once we have created an experiment, we can run a training.\n",
    "\n",
    "A training requires a `load_dataset`, `build_loss` and `build_optimizer`.\n",
    "These are either dicts or callables that create the respective parts.\n",
    "In the case of a dict, the type attribute is the class that should be instantiated and other entries are arguments to the constructor.\n",
    "\n",
    "* `build_loss`: Is expected to return a loss. Either a callable `def build_loss(experiment) -> Union[Loss, Module]` or a dict specification for a class of type `Union[Loss, Module]`.\n",
    "* `build_optimizer`: Is expected to return a torch.optim.Optimizer. Either a callable `def build_optimizer(experiment) -> Optim` or a dict specification for a class of type `Optim`.\n",
    "* `load_dataset`: Is expected to return a a Dataset. Either a callable `def build_train_dataset(experiment, split) -> Dataset` or a dict specification for a class with a constructor `__init__(split, **kwargs)`.\n",
    "\n",
    "Depending on how your dataset and loss are already implemented the callback or dict implementation is easier to use.\n",
    "Since we use the pre-implemented versions of leanai, we will choose the dict option.\n",
    "\n",
    "Lastly, do not forget to specify your `batch_size` and `epochs`, which are technically optional, but you should always need them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68641878-249c-4583-8238-0e1e9bc3e2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/fuerst/.miniconda3/envs/ssf/lib/python3.8/site-packages/torch/_jit_internal.py:668: LightningDeprecationWarning: The `LightningModule.loaded_optimizer_states_dict` property is deprecated in v1.4 and will be removed in v1.6.\n",
      "  if hasattr(mod, name):\n",
      "\n",
      "  | Name  | Type                             | Params | In sizes       | Out sizes\n",
      "----------------------------------------------------------------------------------------\n",
      "0 | model | SequentialModel                  | 8.6 K  | [2, 28, 28, 1] | [2, 10]  \n",
      "1 | loss  | SparseCrossEntropyLossFromLogits | 0      | ?              | ?        \n",
      "----------------------------------------------------------------------------------------\n",
      "8.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.6 K     Total params\n",
      "0.034     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "896be75217424114a9f3346412160cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment.run_training(\n",
    "    load_dataset=DictLike(\n",
    "        type=FashionMNISTDataset,\n",
    "        data_path=\"outputs\",\n",
    "    ),\n",
    "    build_loss=DictLike(\n",
    "        type=SparseCrossEntropyLossFromLogits,\n",
    "    ),\n",
    "    build_optimizer=DictLike(\n",
    "        type=SGD,\n",
    "        lr=1e-3,\n",
    "    ),\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfd6046-a3bd-4969-8ffd-96671e9c9d43",
   "metadata": {},
   "source": [
    "## Wrap-Up\n",
    "\n",
    "That is it for the tutorial. You might want to have a look at tensorboard though. Here you go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "176567ac-8266-4960-9bad-63cb894674d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-629f6fbed82c07cd\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-629f6fbed82c07cd\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cc53ac-0887-4c5d-a052-4dc6bf11e78e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (SSF)",
   "language": "python",
   "name": "ssf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
